# The Environmental Impact of AI

# Energy Consumption of AI: Trends, Impacts, and Sustainability

## Growing Energy Demand of Large AI Models  
The computational requirements of artificial intelligence have skyrocketed with the rise of large-scale models. GPT-4, for example, is reported to have **around 1.8 trillion parameters**, over 6× more than GPT-3’s 175 billion and **1,200×** more than GPT-2 ([Understanding AI Energy Consumption: Trends and Strategies](https://www.eweek.com/artificial-intelligence/ai-energy-consumption/#:~:text=great%20deal%20of%20computation%20resources,4)). This massive scale translates into enormous energy needs. Training GPT-3 consumed roughly **1,287 MWh** of electricity – about as much power as **120 average U.S. homes use in a year** ([Understanding AI Energy Consumption: Trends and Strategies](https://www.eweek.com/artificial-intelligence/ai-energy-consumption/#:~:text=great%20deal%20of%20computation%20resources,4)) ([AI Energy Consumption: How Much Power AI Models Like GPT-4 Are Using (New Stats) | PatentPC](https://patentpc.com/blog/ai-energy-consumption-how-much-power-ai-models-like-gpt-4-are-using-new-stats#:~:text=7.%20Training%20GPT,metric%20tons%20of%20CO%E2%82%82%20emissions)). GPT-4’s training likely required even more energy given its size ([Understanding AI Energy Consumption: Trends and Strategies](https://www.eweek.com/artificial-intelligence/ai-energy-consumption/#:~:text=great%20deal%20of%20computation%20resources,4)). Such energy-intensive training runs have become increasingly common as model sizes and data volumes grow. In fact, the computing power used for cutting-edge AI has been **doubling roughly every 100 days**, far outpacing Moore’s Law ([How to manage AI's energy demand — today and in the future | World Economic Forum](https://www.weforum.org/stories/2024/04/how-to-manage-ais-energy-demand-today-tomorrow-and-in-the-future/#:~:text=AI%20and%20energy%20demand)). One analysis projects that by **2028** the power draw of AI could exceed the **entire electricity consumption of Iceland (as of 2021) ([How to manage AI's energy demand — today and in the future | World Economic Forum](https://www.weforum.org/stories/2024/04/how-to-manage-ais-energy-demand-today-tomorrow-and-in-the-future/#:~:text=Remarkably%2C%20the%20computational%20power%20required,of%20Iceland%20used%20in%202021))**. 

This trend is driving a surge in data center energy use. What was once relatively stable has **“skyrocketed with the AI boom,”** and global data center power demand is forecast to grow **160% by 2030** due in large part to AI workloads ([Understanding AI Energy Consumption: Trends and Strategies](https://www.eweek.com/artificial-intelligence/ai-energy-consumption/#:~:text=Then%20there%20are%20the%20data,on%20and%20the%20hardware%20cool)). Industry estimates already suggest data centers (many running AI services) consume on the order of **1–2% of the world’s electricity** ([AI Energy Consumption: How Much Power AI Models Like GPT-4 Are Using (New Stats) | PatentPC](https://patentpc.com/blog/ai-energy-consumption-how-much-power-ai-models-like-gpt-4-are-using-new-stats#:~:text=5,of%20global%20electricity%20usage)), and climbing. A BBC report even warned that by 2027 the **AI industry may draw more power annually than an entire country (the Netherlands) ([Understanding AI Energy Consumption: Trends and Strategies](https://www.eweek.com/artificial-intelligence/ai-energy-consumption/#:~:text=Massachusetts%20www,environmental%20degradation%20is%20deeply%20concerning))**. In short, as AI models and usage proliferate, so do their energy appetites – raising significant sustainability concerns.

## Energy Use: Training vs. Inference (and Other AI Tasks)  
AI’s energy consumption can be divided into the **training phase** (building the model) and the **inference phase** (running the model for predictions or user queries). While one might assume training dominates, it is often a one-time (if extremely large) expense, whereas inference happens continuously. In practice, **inference now accounts for the lion’s share – about 80% – of AI’s total energy footprint, vs. ~20% for training ([How to manage AI's energy demand — today and in the future | World Economic Forum](https://www.weforum.org/stories/2024/04/how-to-manage-ais-energy-demand-today-tomorrow-and-in-the-future/#:~:text=The%20AI%20lifecycle%20impacts%20the,its%20environmental%20footprint%20will%20escalate))**. Google engineers similarly estimated about **60% of AI energy goes to inference** in production ([AI’s Growing Carbon Footprint – State of the Planet](https://news.climate.columbia.edu/2023/06/09/ais-growing-carbon-footprint/#:~:text=training,of%20CO2%20in%20a%20year)). The reason is scale: a model may be trained once or periodically, but then used millions or billions of times by end-users. For example, **GPT-3’s daily usage was estimated at ~50 lbs of CO₂ emissions (8.4 tons in a year) ([AI’s Growing Carbon Footprint – State of the Planet](https://news.climate.columbia.edu/2023/06/09/ais-growing-carbon-footprint/#:~:text=training,of%20CO2%20in%20a%20year))**, reflecting the cumulative energy of many inference calls. Two months after launch, ChatGPT reached 100 million users – each query drawing power – so over time the **energy to serve users far exceeds the initial training cost ([AI’s Growing Carbon Footprint – State of the Planet](https://news.climate.columbia.edu/2023/06/09/ais-growing-carbon-footprint/#:~:text=Inference%20energy%20consumption%20is%20high,according%20to%20one%20tech%20expert))**.

**Training** large models remains extremely energy-intensive in its own right. Training the BERT language model on a large dataset required **64 TPU chips running for four days** ([Understanding AI Energy Consumption: Trends and Strategies](https://www.eweek.com/artificial-intelligence/ai-energy-consumption/#:~:text=The%20more%20data%20an%20AI,are%20typically%20the%20most%20energy)), and a University of Massachusetts study calculated that training a single big NLP model (with extensive experimentation) could emit **626,000 pounds of CO₂** – about **5× the lifetime emissions of an average car** ([Understanding AI Energy Consumption: Trends and Strategies](https://www.eweek.com/artificial-intelligence/ai-energy-consumption/#:~:text=sources%20of%20energy%20that%20result,of%20extra%20burden%20this%20will)). OpenAI’s GPT-3 training run consumed an estimated **1,287 MWh** and produced **502 metric tons of CO₂** ([AI Energy Consumption: How Much Power AI Models Like GPT-4 Are Using (New Stats) | PatentPC](https://patentpc.com/blog/ai-energy-consumption-how-much-power-ai-models-like-gpt-4-are-using-new-stats#:~:text=7.%20Training%20GPT,metric%20tons%20of%20CO%E2%82%82%20emissions)). By contrast, **inference** is less intensive per operation but can eclipse training in aggregate. Serving one **ChatGPT query uses nearly 10× more electricity than a typical Google search** ([Understanding AI Energy Consumption: Trends and Strategies](https://www.eweek.com/artificial-intelligence/ai-energy-consumption/#:~:text=The%20main%20determinant%20of%20AI,to%20match%20the%20pace%20of)), because generating a response requires billions of compute operations across a large neural network. (Some experts put this figure even higher in certain cases ([AI’s Growing Carbon Footprint – State of the Planet](https://news.climate.columbia.edu/2023/06/09/ais-growing-carbon-footprint/#:~:text=smaller%20AI%20models%2C%20many%20people,according%20to%20one%20tech%20expert)).) Multiply that by millions of prompts and you see why running the model can dominate total energy use. In research tests, more complex generative tasks can be especially demanding – for instance, generating 1,000 AI images was measured to consume about **2.9 kWh of energy** (on a particular model/setup), which was higher per-inference energy than comparable text tasks ([Sending One Email With ChatGPT is the Equivalent of Consuming One Bottle of Water](https://www.techrepublic.com/article/generative-ai-data-center-water-use/#:~:text=How%20much%20electricity%20does%20it,to%20generate%20an%20AI%20image)). 

Other AI operations also contribute to energy draw: data preprocessing, hyperparameter tuning, and maintaining the **infrastructure** all add overhead. Keeping **AI servers idling and ready** incurs non-trivial energy as well – a single high-end AI server can draw multiple kWh per day even when just hosting a model ([AI Energy Consumption: How Much Power AI Models Like GPT-4 Are Using (New Stats) | PatentPC](https://patentpc.com/blog/ai-energy-consumption-how-much-power-ai-models-like-gpt-4-are-using-new-stats#:~:text=4,per%20day%20per%20server)). In summary, training a modern AI model can be compared to an **energy-intensive “construction project”**, but inference is like operating a heavy-duty machine continuously. Current usage patterns indicate **inference can account for ~80%** of a model’s **lifetime energy consumption ([How to manage AI's energy demand — today and in the future | World Economic Forum](https://www.weforum.org/stories/2024/04/how-to-manage-ais-energy-demand-today-tomorrow-and-in-the-future/#:~:text=The%20AI%20lifecycle%20impacts%20the,its%20environmental%20footprint%20will%20escalate))**, making efficiency in serving AI just as crucial as efficiency in training it.

## Water Usage for AI Data Center Cooling  
Another often-overlooked aspect of AI’s resource consumption is its **water footprint**. Data centers running AI workloads require enormous cooling capacity to dissipate heat from thousands of high-power chips. In many facilities, cooling is achieved with water – lots of it. **Generative AI’s rise is matched by “millions of gallons of water to cool the equipment”** in data centers ([As Use of A.I. Soars, So Does the Energy and Water It Requires](https://e360.yale.edu/features/artificial-intelligence-climate-energy-emissions#:~:text=Requires%20e360,of%20water%20to%20cool)). For example, in **July 2022 – the final month of GPT-4’s training – Microsoft had to pump about 11.5 million gallons of water** from local Iowa watersheds **just to cool the supercomputer** powering the AI ([Artificial intelligence technology behind ChatGPT was built in Iowa — with a lot of water | AP News : r/Iowa](https://www.reddit.com/r/Iowa/comments/16gbhw6/artificial_intelligence_technology_behind_chatgpt/#:~:text=disclosure)). That single month accounted for **~6% of all water usage in the district** (West Des Moines) ([Artificial intelligence technology behind ChatGPT was built in Iowa — with a lot of water | AP News : r/Iowa](https://www.reddit.com/r/Iowa/comments/16gbhw6/artificial_intelligence_technology_behind_chatgpt/#:~:text=,water%20to%20the%20city%E2%80%99s%20residents)). Microsoft’s overall data center water consumption surged **34% in 2022, reaching nearly 1.7 billion gallons (6.4 billion liters)**, largely due to its expanding AI operations ([AI’s hidden thirst or how much water does Artificial Intelligence really drink? – Solveo](https://solveo.co/ais-hidden-thirst-or-how-much-water-does-artificial-intelligence-really-drink/#:~:text=,footprint%20an%20increasingly%20urgent%20issue)). Google’s data centers are similarly water-hungry – one campus in Council Bluffs, Iowa used **about 980 million gallons in 2023** (the highest of any U.S. data center) ([AI’s hidden thirst or how much water does Artificial Intelligence really drink? – Solveo](https://solveo.co/ais-hidden-thirst-or-how-much-water-does-artificial-intelligence-really-drink/#:~:text=,households)). 

Even on a per-interaction level, AI “drinks” notable water behind the scenes. Researchers from UC Riverside estimate that **every 20 to 50 user prompts to ChatGPT consume about 500 milliliters (half a liter) of water** for cooling, when factoring in both direct cooling and the water used by power plants supplying the electricity ([AI’s hidden thirst or how much water does Artificial Intelligence really drink? – Solveo](https://solveo.co/ais-hidden-thirst-or-how-much-water-does-artificial-intelligence-really-drink/#:~:text=Let%E2%80%99s%20break%20it%20down%20further,about%20500%20milliliters%20of%20water)). In other words, a small bottle of water is depleted for a short AI conversation. If one in ten American workers wrote just a single 100-word email using GPT-4 each week, the annual water required is estimated at **435 million liters** – roughly **all the water used in the state of Rhode Island over 1.5 days ([Sending One Email With ChatGPT is the Equivalent of Consuming One Bottle of Water](https://www.techrepublic.com/article/generative-ai-data-center-water-use/#:~:text=,hours%20%28MWh%29%20of%20electricity))**. And recall, **training itself has a water cost**: OpenAI’s GPT-3 training consumed an estimated **700,000 liters** of water (about 185,000 gallons) through cooling and power generation needs ([Sending One Email With ChatGPT is the Equivalent of Consuming One Bottle of Water](https://www.techrepublic.com/article/generative-ai-data-center-water-use/#:~:text=That%E2%80%99s%20the%20same%20amount%20of,took%20700%2C000%20liters%20of%20water)). 

The scale of AI’s water use is becoming a concern, especially in regions facing drought or water scarcity. Data centers often locate where power is cheap, which can be arid areas – raising the risk of **competition with local communities for water resources ([AI’s hidden thirst or how much water does Artificial Intelligence really drink? – Solveo](https://solveo.co/ais-hidden-thirst-or-how-much-water-does-artificial-intelligence-really-drink/#:~:text=water%20increases%2C%20putting%20even%20more,pressure%20on%20local%20supplies))**. Looking forward, the **“water thirst” of AI is poised to grow**. One projection warns that by **2027, AI workloads could consume 4.2 to 6.6 **billion cubic meters** of water annually** (including indirect water use for electricity) if trends continue ([AI’s hidden thirst or how much water does Artificial Intelligence really drink? – Solveo](https://solveo.co/ais-hidden-thirst-or-how-much-water-does-artificial-intelligence-really-drink/#:~:text=It%E2%80%99s%20like%20filling%20up%20a,speed%20we%E2%80%99ve%20come%20to%20expect)). That is trillions of liters – equivalent to the water usage of entire large cities or regions – just to support AI computations. Such figures highlight why the **water footprint** now joins energy as a key environmental consideration for AI. 

## Carbon Footprint and Environmental Impact  
The energy and water consumption of AI translates into a substantial **carbon and ecological footprint**. Because most data centers still draw power from fossil-fueled grids, heavy electricity use means high greenhouse gas emissions. There is a direct link between AI’s energy draw and CO₂ output: **the more power-hungry the model, the more carbon it emits**, unless mitigated by clean energy ([Understanding AI Energy Consumption: Trends and Strategies](https://www.eweek.com/artificial-intelligence/ai-energy-consumption/#:~:text=There%E2%80%99s%20a%20causal%20relationship%20between,industry%20may%20consume%20more%20energy)). Researchers have quantified some eye-opening examples. The **University of Massachusetts study** found that training a single large NLP model (with extensive experimentation) emitted **626,000 lbs of CO₂** (~284 metric tons) – **about five times the lifetime emissions of an average car** ([Understanding AI Energy Consumption: Trends and Strategies](https://www.eweek.com/artificial-intelligence/ai-energy-consumption/#:~:text=sources%20of%20energy%20that%20result,of%20extra%20burden%20this%20will)). OpenAI’s GPT-3, as noted, was responsible for roughly **502 tCO₂ just from training ([AI’s Growing Carbon Footprint – State of the Planet](https://news.climate.columbia.edu/2023/06/09/ais-growing-carbon-footprint/#:~:text=Moving%20large%20jobs%20to%20data,tons%20of%20carbon%20dioxide%20equivalent))**, equivalent to the annual emissions of **hundreds of gasoline cars ([AI Energy Consumption: How Much Power AI Models Like GPT-4 Are Using (New Stats) | PatentPC](https://patentpc.com/blog/ai-energy-consumption-how-much-power-ai-models-like-gpt-4-are-using-new-stats#:~:text=GPT,powered%20cars%20in%20a%20year))**. And these figures don’t yet account for the ongoing emissions from running the model for millions of users afterward.

At the macro level, data centers (across all applications) are estimated to account for **2.5–3.7% of global greenhouse gas emissions**, exceeding even the aviation industry’s share ([AI’s Growing Carbon Footprint – State of the Planet](https://news.climate.columbia.edu/2023/06/09/ais-growing-carbon-footprint/#:~:text=Today%20data%20centers%20run%2024%2F7,those%20of%20the%20aviation%20industry)). AI’s growing footprint is becoming a larger slice of that pie. As companies like OpenAI, Google, and Baidu race to build bigger models and more people use them, the concern is that **AI could make cutting overall CO₂ emissions much harder ([AI’s Growing Carbon Footprint – State of the Planet](https://news.climate.columbia.edu/2023/06/09/ais-growing-carbon-footprint/#:~:text=Northeastern%20University%20and%20MIT%20researchers,our%20societies%20much%20more%20difficult))**. One analysis predicted that by 2027, the energy consumption (and by extension carbon emissions) of the AI sector might outstrip that of some entire countries (e.g. the Netherlands) if unchecked ([Understanding AI Energy Consumption: Trends and Strategies](https://www.eweek.com/artificial-intelligence/ai-energy-consumption/#:~:text=Massachusetts%20www,environmental%20degradation%20is%20deeply%20concerning)). 

Beyond carbon emissions, **AI’s hardware supply chain has environmental impacts**. Manufacturing the thousands of specialized chips (GPUs, TPUs, etc.) for AI requires mining and refining of rare materials and consumes significant energy and water. This contributes to electronic waste and resource depletion. The World Economic Forum projects **e-waste could exceed 120 million metric tons annually by 2050** (the equivalent mass of **nearly 12,000 Eiffel Towers**) ([Understanding AI Energy Consumption: Trends and Strategies](https://www.eweek.com/artificial-intelligence/ai-energy-consumption/#:~:text=Apart%20from%20carbon%20emissions%2C%20the,degradation%20but%20also%20geopolitical%20tension)). The demand for rare earth metals and other components to build AI infrastructure can also lead to habitat disruption and geopolitical tensions over those resources ([Understanding AI Energy Consumption: Trends and Strategies](https://www.eweek.com/artificial-intelligence/ai-energy-consumption/#:~:text=Apart%20from%20carbon%20emissions%2C%20the,degradation%20but%20also%20geopolitical%20tension)). Additionally, the strain on power grids and water supplies in certain locales can **impact local environments and public health** – for instance, increased air pollution from power generation or reduced water availability in drought-prone areas ([AI’s hidden thirst or how much water does Artificial Intelligence really drink? – Solveo](https://solveo.co/ais-hidden-thirst-or-how-much-water-does-artificial-intelligence-really-drink/#:~:text=water%20increases%2C%20putting%20even%20more,pressure%20on%20local%20supplies)) ([Understanding AI Energy Consumption: Trends and Strategies](https://www.eweek.com/artificial-intelligence/ai-energy-consumption/#:~:text=There%E2%80%99s%20a%20causal%20relationship%20between,industry%20may%20consume%20more%20energy)). All these factors raise the question of **sustainability**: How can we continue to advance AI without unsustainable environmental costs?

## Toward Sustainable AI: Mitigation Efforts and Solutions  
Recognizing these challenges, researchers and industry leaders are exploring numerous strategies to **mitigate the environmental costs of AI**. A key approach is improving **efficiency** at all levels:

- **Smarter Model Design:** AI scientists are adopting techniques like *model pruning*, *knowledge distillation*, and *quantization* to make neural networks leaner. Pruning removes redundant parameters, and distillation trains smaller models to replicate larger ones’ behavior. *Quantization*, which uses lower-precision calculations, can cut computation requirements drastically – studies show it can save **up to 50% of the computational cost** with minimal accuracy loss ([Understanding AI Energy Consumption: Trends and Strategies](https://www.eweek.com/artificial-intelligence/ai-energy-consumption/#:~:text=the%20AI%20development%20community)). By using these methods, companies can deploy models that achieve similar results with far less energy. There’s also emphasis on choosing the **right-sized model for the task** – using a massive 175B-parameter model for every little task is wasteful if a smaller model or more traditional algorithm would suffice ([AI’s Growing Carbon Footprint – State of the Planet](https://news.climate.columbia.edu/2023/06/09/ais-growing-carbon-footprint/#:~:text=The%20appropriate%20model)).

- **Efficient Hardware:** Hardware innovation is another pillar of sustainable AI. Specialized AI chips are being developed to deliver more performance per watt. For instance, **NVIDIA’s H100 GPU offers improved throughput per unit of power compared to the A100** (which itself draws up to 400 W per chip) ([Understanding AI Energy Consumption: Trends and Strategies](https://www.eweek.com/artificial-intelligence/ai-energy-consumption/#:~:text=NVIDIA%E2%80%99s%20A100%20GPU%2C%20used%20in,less%20energy%20than%20previous%20generations)). Google’s **TPU (Tensor Processing Unit)** is designed for efficiency in training large models and can outperform general GPUs in both speed and energy use ([AI’s Growing Carbon Footprint – State of the Planet](https://news.climate.columbia.edu/2023/06/09/ais-growing-carbon-footprint/#:~:text=More%20efficient%20hardware)). As a result, the **energy cost per AI operation drops** with each hardware generation. Companies are also turning to *accelerators for inference* – chips optimized to run trained models faster and with lower power, which is critical since inference constitutes ~80% of AI’s energy usage ([How to manage AI's energy demand — today and in the future | World Economic Forum](https://www.weforum.org/stories/2024/04/how-to-manage-ais-energy-demand-today-tomorrow-and-in-the-future/#:~:text=The%20AI%20lifecycle%20impacts%20the,its%20environmental%20footprint%20will%20escalate)). On the data center side, operators are using **liquid cooling and advanced cooling designs** to reduce the power needed for cooling. Some new systems cool chips directly (at the server rack or chip level) rather than chilling whole rooms, which improves efficiency. For example, Microsoft in 2024 launched a **“zero-water” cooling design that uses a closed-loop liquid system**, eliminating evaporative cooling. Each such data center can save over **125 million liters of water per year** by not using fresh water for cooling ([Sustainable by design: Next-generation datacenters consume zero water for cooling | The Microsoft Cloud Blog](https://www.microsoft.com/en-us/microsoft-cloud/blog/2024/12/09/sustainable-by-design-next-generation-datacenters-consume-zero-water-for-cooling/#:~:text=Beginning%20in%20August%202024%2C%20Microsoft,water%20per%20year%20per%20datacenter)). Microsoft reports this and other optimizations have already improved its data centers’ water efficiency by **39% (WUE down to 0.30 L/kWh)** in recent years ([Sustainable by design: Next-generation datacenters consume zero water for cooling | The Microsoft Cloud Blog](https://www.microsoft.com/en-us/microsoft-cloud/blog/2024/12/09/sustainable-by-design-next-generation-datacenters-consume-zero-water-for-cooling/#:~:text=We%20measure%20water%20efficiency%20through,actively%20reduce%20water%20wastage%2C%20expand)).

- **Renewable Energy and Carbon Offsets:** A direct way to cut AI’s carbon footprint is to power it with clean energy. Major cloud providers are increasingly investing in renewable power for their data centers. Microsoft, Google, Amazon, and others have pledged to reach **100% carbon-free or renewable energy for data centers by 2030** (with some claiming to already match 100% of their usage with renewable purchases today) ([AI’s Growing Carbon Footprint – State of the Planet](https://news.climate.columbia.edu/2023/06/09/ais-growing-carbon-footprint/#:~:text=Renewable%20energy%20use)). Google reports that its data centers already offset *all* their electricity with renewables ([AI’s Growing Carbon Footprint – State of the Planet](https://news.climate.columbia.edu/2023/06/09/ais-growing-carbon-footprint/#:~:text=According%20to%20Microsoft%2C%20all%20the,their%20energy%20from%20renewable%20sources)), and Microsoft aims to run on **100% renewable power by 2025** for its cloud operations ([AI’s Growing Carbon Footprint – State of the Planet](https://news.climate.columbia.edu/2023/06/09/ais-growing-carbon-footprint/#:~:text=Renewable%20energy%20use)). Additionally, companies are using tools to monitor and manage emissions – for example, Microsoft’s Azure **Emissions Impact Dashboard** helps cloud customers track the CO₂ from their AI workloads ([AI’s Growing Carbon Footprint – State of the Planet](https://news.climate.columbia.edu/2023/06/09/ais-growing-carbon-footprint/#:~:text=You%20can%E2%80%99t%20solve%20a%20problem,users%20to%20calculate%20their%20cloud%E2%80%99s)). Such transparency and reporting is increasingly encouraged, so that organizations can **select lower-carbon options** (like scheduling jobs in regions or times when green energy is abundant) and purchase carbon offsets for the remainder. Researchers have even developed independent trackers to measure AI training energy and emissions for academic models, pushing for more open reporting of AI’s environmental impact ([AI’s Growing Carbon Footprint – State of the Planet](https://news.climate.columbia.edu/2023/06/09/ais-growing-carbon-footprint/#:~:text=You%20can%E2%80%99t%20solve%20a%20problem,users%20to%20calculate%20their%20cloud%E2%80%99s)).

- **Intelligent Scheduling and Optimization:** Efficiency isn’t just about hardware – *when* and *how* we run AI jobs can make a difference. Strategically scheduling AI computations for times of lower demand or cooler ambient temperatures can reduce stress on the grid and cooling systems ([How to manage AI's energy demand — today and in the future | World Economic Forum](https://www.weforum.org/stories/2024/04/how-to-manage-ais-energy-demand-today-tomorrow-and-in-the-future/#:~:text=Research%20is%20emerging%20about%20the,longer)). For instance, non-urgent training jobs could run overnight or in cooler seasons to save on air conditioning energy ([AI’s Growing Carbon Footprint – State of the Planet](https://news.climate.columbia.edu/2023/06/09/ais-growing-carbon-footprint/#:~:text=He%20is%20also%20currently%20researching,computers%20need%20to%20run%20quickly)). *Dynamic scaling* of cloud resources is another tactic: scaling servers down when demand lulls so they don’t waste energy idling ([AI Energy Consumption: How Much Power AI Models Like GPT-4 Are Using (New Stats) | PatentPC](https://patentpc.com/blog/ai-energy-consumption-how-much-power-ai-models-like-gpt-4-are-using-new-stats#:~:text=Some%20ways%20to%20manage%20this,include)). Some data centers use AI itself to optimize operations – Google famously applied DeepMind AI to its HVAC controls and achieved a **40% reduction in cooling energy** ([AI’s hidden thirst or how much water does Artificial Intelligence really drink? – Solveo](https://solveo.co/ais-hidden-thirst-or-how-much-water-does-artificial-intelligence-really-drink/#:~:text=various%20industries%2C%20so%20why%20not,it%20to%20its%20own%20operations)). That not only saves electricity but also the associated water for cooling. Similarly, AI-driven predictive maintenance can detect cooling inefficiencies or leaks early, preventing waste ([AI’s hidden thirst or how much water does Artificial Intelligence really drink? – Solveo](https://solveo.co/ais-hidden-thirst-or-how-much-water-does-artificial-intelligence-really-drink/#:~:text=,like%20solar%20and%20wind%2C%20which)). In essence, there’s a feedback loop where AI can be used to improve the sustainability of AI operations.

- **Innovations in Cooling and Water Recycling:** Given AI’s heavy water usage, companies are innovating on that front too. Apart from the zero-water cooling mentioned, data center operators are exploring using **recycled or non-potable water** for cooling instead of tapping municipal fresh water ([AI’s hidden thirst or how much water does Artificial Intelligence really drink? – Solveo](https://solveo.co/ais-hidden-thirst-or-how-much-water-does-artificial-intelligence-really-drink/#:~:text=various%20industries%2C%20so%20why%20not,it%20to%20its%20own%20operations)). Some are locating data centers near large water sources or in cooler climates to reduce cooling needs. Others experiment with **submersion cooling** (immersing servers in special fluids) to drastically cut both electricity and water required for cooling. These efforts aim to curb AI’s **“hidden thirst”** so that even as compute grows, it doesn’t dry up local water supplies.

The **case of BLOOM vs GPT-3** illustrates multiple sustainability strategies in action. BLOOM is an open large language model with 176 billion parameters, comparable in size to GPT-3. By training BLOOM on a French supercomputer largely powered by nuclear (low-carbon) energy, the project kept its emissions to just **25 metric tons of CO₂ for 433 MWh of energy used ([AI’s Growing Carbon Footprint – State of the Planet](https://news.climate.columbia.edu/2023/06/09/ais-growing-carbon-footprint/#:~:text=Moving%20large%20jobs%20to%20data,tons%20of%20carbon%20dioxide%20equivalent))**. In contrast, GPT-3’s training on a mostly fossil-powered grid produced **502 tCO₂ from 1,287 MWh ([AI’s Growing Carbon Footprint – State of the Planet](https://news.climate.columbia.edu/2023/06/09/ais-growing-carbon-footprint/#:~:text=Moving%20large%20jobs%20to%20data,tons%20of%20carbon%20dioxide%20equivalent))**. In other words, BLOOM achieved a similar scale with **~5% of the carbon footprint** of GPT-3 by leveraging cleaner energy and efficient infrastructure. This kind of case study underscores that **where and how** we train models can make a huge difference. 

Finally, the AI community is increasingly aware of these issues. Workshops on “Green AI” and energy-efficient machine learning have emerged, and conferences now encourage authors to report energy usage for new models. There is recognition that progress in AI should be measured not only in accuracy or capability but also in **compute efficiency**. As one expert put it, we’re entering a phase where we must **“be aware of the energy usage…and take that into our calculations of whether we should be doing it”** ([AI’s Growing Carbon Footprint – State of the Planet](https://news.climate.columbia.edu/2023/06/09/ais-growing-carbon-footprint/#:~:text=%E2%80%98amazed%20by%20what%20we%20can,%E2%80%9D)). In response, researchers are developing tools to estimate and **budget the carbon cost** of AI projects upfront, and exploring techniques to **“stop early”** in training when additional cycles yield diminishing returns ([AI’s Growing Carbon Footprint – State of the Planet](https://news.climate.columbia.edu/2023/06/09/ais-growing-carbon-footprint/#:~:text=Another%20area%20of%20Stein%E2%80%99s%20research,The%20challenge%20is)). All these efforts, from efficient algorithms and hardware to green energy and cooling, are aimed at **bending the curve** of AI’s environmental impact. The goal is to enable continued AI innovation while ensuring its energy and resource demands become sustainable in the long run ([Understanding AI Energy Consumption: Trends and Strategies](https://www.eweek.com/artificial-intelligence/ai-energy-consumption/#:~:text=KEY%20TAKEAWAYS)) ([How to manage AI's energy demand — today and in the future | World Economic Forum](https://www.weforum.org/stories/2024/04/how-to-manage-ais-energy-demand-today-tomorrow-and-in-the-future/#:~:text=,AI%20and%20the%20green%20transition)).

I will research DeepSeek’s approach to energy-efficient AI and whether its methods can contribute to improving the efficiency of other AI models. This will include comparisons with existing models, insights into its architectural advancements, and whether its techniques depend on distilling larger models or if they are independently innovative. I’ll share my findings with you soon.

# DeepSeek’s Approach to Cost-Effective, Energy-Efficient AI

## Energy Consumption: DeepSeek vs Large-Scale AI Models  
DeepSeek, a small Chinese AI firm founded in 2023, has stunned the tech industry by producing open-source AI models with capabilities comparable to state-of-the-art systems like OpenAI’s GPT-4 and Anthropic’s Claude – but at a fraction of the cost and energy use ([DeepSeek: How a small AI company is shaking up US tech giants](https://usa.inquirer.net/165295/deepseek-how-a-small-chinese-ai-company-is-shaking-up-us-tech-heavyweights#:~:text=V3%20was%20trained%20at%20a,than%20US%24100%20million%20to%20develop)). Traditional large language models (LLMs) such as GPT-4, Google’s upcoming *Gemini*, and Meta’s LLaMA demand massive computational resources. For example, GPT-4 is rumored to have over a trillion parameters and required **thousands to tens of thousands of GPUs** running for many months (potentially up to a year) to train ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=The%20main%20reason%20is%20driven,consumes%20a%20lot%20of%20energy)) ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=We%20are%20not%20just%20talking,such%20as%20Nvidia%20and%20AMD)). This scale of training consumes enormous electricity, contributing significantly to carbon emissions ([What is open-source AI and how could DeepSeek change the industry? | World Economic Forum](https://www.weforum.org/stories/2025/02/open-source-ai-innovation-deepseek/#:~:text=If%20it%27s%20shorter%20and%20less,towards%20more%20sustainable%20AI%20scaling)). By contrast, DeepSeek’s latest models were developed with dramatically lower hardware counts and training time. Its *V3* model (a standard LLM released in late 2024) was reportedly trained in about **2 months on only ~2,000 Nvidia H800 GPUs**, costing around **$5.6 million** ([DeepSeek: How a small AI company is shaking up US tech giants](https://usa.inquirer.net/165295/deepseek-how-a-small-chinese-ai-company-is-shaking-up-us-tech-heavyweights#:~:text=V3%20was%20trained%20at%20a,than%20US%24100%20million%20to%20develop)) ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=I%20n%20DeepSeek%E2%80%99s%20technical%20paper%2C,relatively%20short%20time%20is%20impressive)). This is roughly an order of magnitude less compute (and budget) than competitors: **just ~10% of the cost of Meta’s LLaMA** to build ([What is open-source AI and how could DeepSeek change the industry? | World Economic Forum](https://www.weforum.org/stories/2025/02/open-source-ai-innovation-deepseek/#:~:text=Another%20key%20differentiator%20of%20DeepSeek,of%20January%20as%20a%20result)), and far below the >$100 million estimated spent on GPT-4’s training ([DeepSeek: How a small AI company is shaking up US tech giants](https://usa.inquirer.net/165295/deepseek-how-a-small-chinese-ai-company-is-shaking-up-us-tech-heavyweights#:~:text=V3%20was%20trained%20at%20a,than%20US%24100%20million%20to%20develop)). In practice, DeepSeek’s training cluster (2,000 H800 chips) was *one-eighth* the size of those used for leading U.S. models, which often deploy **16,000 or more top-tier GPUs** ([DeepSeek: How a small AI company is shaking up US tech giants](https://usa.inquirer.net/165295/deepseek-how-a-small-chinese-ai-company-is-shaking-up-us-tech-heavyweights#:~:text=DeepSeek%20also%20claims%20to%20have,the%20more%20powerful%20H100%20chips)). Despite the lighter compute, DeepSeek’s *R1* model (released Jan 2025) demonstrated **reasoning and math performance on par with OpenAI’s latest models** ([What is open-source AI and how could DeepSeek change the industry? | World Economic Forum](https://www.weforum.org/stories/2025/02/open-source-ai-innovation-deepseek/#:~:text=Based%20in%20Hangzhou%20and%20funded,differences%20on%20how%20it%20developed)) ([What is open-source AI and how could DeepSeek change the industry? | World Economic Forum](https://www.weforum.org/stories/2025/02/open-source-ai-innovation-deepseek/#:~:text=Another%20key%20differentiator%20of%20DeepSeek,of%20January%20as%20a%20result)). This impressive efficiency – achieving similar AI capability with a tenth or less of the energy investment – has significant implications. In the short term it even jolted markets, as investors realized more efficient AI could undercut the assumed need for ever-expanding GPU farms ([Nvidia says DeepSeek advances prove need for more of its chips | Reuters](https://www.reuters.com/technology/nvidia-says-deepseek-advances-prove-need-more-its-chips-2025-01-27/#:~:text=Nvidia%20issued%20a%20statement%20on,to%20%24115.01)) ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=We%20have%20seen%20the%20release,better%20cost%20and%20energy%20efficiency)). Overall, DeepSeek’s models highlight that smart research and engineering can drastically reduce energy consumption relative to the giant-scale GPT-4, Gemini, or LLaMA, **delivering comparable AI performance with far lower power draw** ([DeepSeek: How a small AI company is shaking up US tech giants](https://usa.inquirer.net/165295/deepseek-how-a-small-chinese-ai-company-is-shaking-up-us-tech-heavyweights#:~:text=V3%20was%20trained%20at%20a,than%20US%24100%20million%20to%20develop)).

## Techniques Enabling DeepSeek’s Efficiency  
DeepSeek’s ability to cut computational cost and energy use comes from several **technological innovations and training strategies** that maintain performance while using fewer resources. A cornerstone of their approach is a novel **large-scale reinforcement learning paradigm**. In their technical report, DeepSeek describes a method called *DeepSeek-R1-Zero*, inspired by Google’s AlphaZero, which taught their language model through self-play and trial-and-error *without* the usual costly supervised fine-tuning phase ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=D%20eepSeek%20has%20a%20model,effective%2C%20but%20it%E2%80%99s%20quite%20costly)). In essence, the model learned by exploring problems and **teaching itself**, verifying its answers and adjusting its strategy, much like AlphaZero mastered Go through millions of self-play games ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=D%20eepSeek%20has%20a%20model,effective%2C%20but%20it%E2%80%99s%20quite%20costly)) ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=To%20their%20and%20our%20surprise%2C,use%20some%20conventional%20techniques%20too)). This allowed DeepSeek to reach high reasoning performance quickly, bypassing the need for extensive human-labeled datasets (which require many training cycles and human labor) ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=D%20eepSeek%20has%20a%20model,effective%2C%20but%20it%E2%80%99s%20quite%20costly)). Observers note that this large-scale **reinforcement learning (RL) training** converged surprisingly well – the RL-driven “reasoning” model (DeepSeek-R1) achieved quality comparable to much larger models but with a smaller, more efficient training process ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=To%20their%20and%20our%20surprise%2C,use%20some%20conventional%20techniques%20too)). 

Equally important, DeepSeek employed **advanced model architecture and optimization techniques** to boost efficiency. Their researchers leveraged a **Mixture-of-Experts (MoE)** design, which activates only subsets of the model’s parameters for a given query ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=a%20quick%20path%20to%20reach,use%20some%20conventional%20techniques%20too)). This means the effective compute per inference can be lower, and it allows a very large model to be trained without using all its parts at once, saving energy. (It’s notable that DeepSeek’s model reportedly exceeds 600 billion parameters, which is huge – yet MoE and clever training meant it could be handled with fewer chips ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=DeepSeek%20mentioned%20they%20spent%20less,time%20and%20resource%20for%20training)) ([DeepSeek: How a small AI company is shaking up US tech giants](https://usa.inquirer.net/165295/deepseek-how-a-small-chinese-ai-company-is-shaking-up-us-tech-heavyweights#:~:text=DeepSeek%20also%20claims%20to%20have,the%20more%20powerful%20H100%20chips)).) They also utilized **low-precision computation and quantization** methods ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=a%20quick%20path%20to%20reach,use%20some%20conventional%20techniques%20too)). By training with reduced numerical precision (for example, 8-bit or 16-bit floating point instead of 32-bit), DeepSeek cut down memory and power usage while speeding up training. This *did not* significantly hurt accuracy thanks to careful calibration, but it slashed the energy per operation. Additionally, DeepSeek optimized their distributed training with effective **load balancing across GPUs** ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=a%20quick%20path%20to%20reach,use%20some%20conventional%20techniques%20too)) – ensuring no chip sat idle and every watt contributed to model improvement. All these measures combined to produce a training pipeline that was **highly resource-efficient**, allowing DeepSeek to reach state-of-the-art performance “on the cheap.” As one expert noted, DeepSeek’s team identified ways to make training *converge faster*, using less computation overall – an approach from which “Meta, OpenAI, Google and others can borrow ideas” to cut their own energy use ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=Their%C2%A0training%20algorithm%20and%20strategy%20may,move%20forward%20faster%20and%20cheaper)). In summary, **innovations like self-play RL, MoE architectures, and aggressive optimization** enabled DeepSeek’s models to **match the prowess of giant LLMs while consuming far less energy** ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=To%20their%20and%20our%20surprise%2C,use%20some%20conventional%20techniques%20too)).

## Applying DeepSeek’s Strategies to Other AI Models  
The success of DeepSeek’s models has prompted the question: can these **efficiency gains be replicated** to improve other AI systems’ energy consumption? The answer appears to be *yes – at least partially*. DeepSeek’s approach has been open-sourced, with the code and a detailed technical paper publicly released ([What is open-source AI and how could DeepSeek change the industry? | World Economic Forum](https://www.weforum.org/stories/2025/02/open-source-ai-innovation-deepseek/#:~:text=Unlike%20OpenAI%E2%80%99s%20ChatGPT%20and%20Anthropic%E2%80%99s,to%20access%2C%20modify%20and%20implement)) ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=DeepSeek%20mentioned%20they%20spent%20less,time%20and%20resource%20for%20training)). This transparency means researchers and competing AI labs can study and adopt its methods. Industry experts view this as a positive development for the AI field at large. If even some of DeepSeek’s techniques are generalized, we could see substantial reductions in training cost and power usage beyond just one company’s models. Professor Haohuan Fu (University of Illinois) points out that since DeepSeek “wrote a detailed paper, people can verify their claim easily” and potentially reproduce the results ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=DeepSeek%20mentioned%20they%20spent%20less,time%20and%20resource%20for%20training)). He notes there is “no reason to lie” about the efficiency because everything is out in the open, and indeed others might implement similar ideas ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=DeepSeek%20mentioned%20they%20spent%20less,time%20and%20resource%20for%20training)). In fact, **major AI players are already motivated to respond**. The emergence of DeepSeek has signaled that training cutting-edge models need not require blank-check budgets and enormous energy—this is pushing firms like OpenAI, Google, Meta, and Anthropic to pursue **“smarter, not just bigger”** strategies ([What DeepSeek Means for AI Energy Demand - Heatmap News](https://heatmap.news/energy/deepseek-ai-energy-demand#:~:text=Another%20factor%20that%20could%20influence,efficient%20vehicle.%E2%80%9D)) ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=We%20have%20seen%20the%20release,better%20cost%20and%20energy%20efficiency)). For example, instead of relying solely on brute-force scale, they may incorporate more efficient algorithms, better chip utilization, or hybrid training paradigms influenced by DeepSeek. Even a **2× improvement** in energy efficiency for big models (far less than DeepSeek’s 10× claim) would be highly significant in reducing costs and carbon footprints ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=training%20can%20converge%20faster,move%20forward%20faster%20and%20cheaper)). The open-source nature of DeepSeek’s model (unusual for a model of this caliber) further means **any developer or organization can build on it** ([What is open-source AI and how could DeepSeek change the industry? | World Economic Forum](https://www.weforum.org/stories/2025/02/open-source-ai-innovation-deepseek/#:~:text=Unlike%20OpenAI%E2%80%99s%20ChatGPT%20and%20Anthropic%E2%80%99s,to%20access%2C%20modify%20and%20implement)). This could democratize AI development, allowing smaller companies and researchers to fine-tune or extend DeepSeek’s models for their needs without needing enormous compute resources. In short, DeepSeek’s efficiency strategies – from novel RL training to quantization – are *largely transferable*, and we are likely to see other AI models **adopt similar optimizations to cut energy consumption**. DeepSeek has effectively provided a blueprint for more sustainable AI, and rivals will not ignore a method that can save them tens of millions in GPU time ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=Their%C2%A0training%20algorithm%20and%20strategy%20may,move%20forward%20faster%20and%20cheaper)). As one analysis put it, if companies can reduce training cost and energy “even if not by ten times, but just by two times,” it will have a huge impact on the industry’s economics and environmental footprint ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=training%20can%20converge%20faster,move%20forward%20faster%20and%20cheaper)).

## Independence or Distillation? DeepSeek’s Knowledge Sources  
A debate has arisen over whether DeepSeek’s breakthroughs are purely a result of independent innovation or if they **leveraged knowledge from existing large models** (so-called *knowledge distillation*). On one hand, DeepSeek’s team and supporters highlight the originality of their approach: the models were built with new algorithms and trained on open data, and the results were achieved with limited compute through clever techniques ([Nvidia says DeepSeek advances prove need for more of its chips | Reuters](https://www.reuters.com/technology/nvidia-says-deepseek-advances-prove-need-more-its-chips-2025-01-27/#:~:text=,Nvidia%20said%20in%20its%20statement)) ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=D%20eepSeek%20has%20a%20model,effective%2C%20but%20it%E2%80%99s%20quite%20costly)). Nvidia – whose chips DeepSeek used – stated that *“new models can be created using [this] technique, leveraging widely-available models and compute”* ([Nvidia says DeepSeek advances prove need for more of its chips | Reuters](https://www.reuters.com/technology/nvidia-says-deepseek-advances-prove-need-more-its-chips-2025-01-27/#:~:text=,Nvidia%20said%20in%20its%20statement)), implying DeepSeek built on publicly known architectures and legally available resources, rather than any secret stolen advantage. Indeed, nothing in DeepSeek’s open technical paper suggests they had access to proprietary weights from GPT-4 or other U.S. models; the success appears to stem from their **reinforcement learning and MoE recipe**, not a direct copy of another model’s parameters ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=D%20eepSeek%20has%20a%20model,effective%2C%20but%20it%E2%80%99s%20quite%20costly)) ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=To%20their%20and%20our%20surprise%2C,use%20some%20conventional%20techniques%20too)). In this sense, DeepSeek’s model can be viewed as an *independent innovation* that stands on the shoulders of general AI research (transformer architectures, open datasets, etc.) but contributes its own advancements.

However, **major AI firms have raised suspicions** that DeepSeek may have also employed *model distillation via API access* to accelerate its training. *Distillation* in this context means using a large “teacher” model’s outputs to train a smaller “student” model, essentially extracting knowledge by querying the teacher extensively ([Did China’s DeepSeek improperly obtain data?  ](https://www.studentnewsdaily.com/daily-news-article/did-chinas-deepseek-improperly-obtain-data/#:~:text=,scale%20knowledge%20transfer)) ([Did China’s DeepSeek improperly obtain data?  ](https://www.studentnewsdaily.com/daily-news-article/did-chinas-deepseek-improperly-obtain-data/#:~:text=The%20ChatGPT%20maker%20said%20it,model%20to%20a%20smaller%20model)). OpenAI has said it is **investigating whether DeepSeek “inappropriately distilled” its models** – i.e. whether DeepSeek queried OpenAI’s GPT-4/ChatGPT and fed the answers into its own training process ([Did China’s DeepSeek improperly obtain data?  ](https://www.studentnewsdaily.com/daily-news-article/did-chinas-deepseek-improperly-obtain-data/#:~:text=The%20ChatGPT%20maker%20said%20it,model%20to%20a%20smaller%20model)). According to reporting, groups in China were known to be “actively working to…replicate advanced U.S. AI models” via distillation of ChatGPT, and OpenAI’s terms of service explicitly forbid using its API output to develop competing models ([Did China’s DeepSeek improperly obtain data?  ](https://www.studentnewsdaily.com/daily-news-article/did-chinas-deepseek-improperly-obtain-data/#:~:text=It%20isn%E2%80%99t%20illegal%2C%20as%20far,%E2%80%9D%20%28from%20Vice)) ([Did China’s DeepSeek improperly obtain data?  ](https://www.studentnewsdaily.com/daily-news-article/did-chinas-deepseek-improperly-obtain-data/#:~:text=The%20ChatGPT%20maker%20said%20it,model%20to%20a%20smaller%20model)). There is even talk that Microsoft researchers observed unusually large volumes of queries from accounts potentially tied to DeepSeek last year ([Did China’s DeepSeek improperly obtain data?  ](https://www.studentnewsdaily.com/daily-news-article/did-chinas-deepseek-improperly-obtain-data/#:~:text=Microsoft%2C%20a%20close%20partner%20of,interface%20last%20fall%2C%C2%A0according%20to%20Bloomberg)). While **none of these claims are definitively proven**, they suggest DeepSeek may have supplemented its novel training techniques with knowledge transferred from frontier models like GPT-4. If true, this would mean DeepSeek’s efficiency partly came from *avoiding retraining what GPT-4 already knew*, instead **learning from GPT-4’s answers** – a shortcut to high performance without all the energy expense of discovering those insights from scratch. DeepSeek has not publicly detailed its data sources beyond saying it used web data and its own methods, so the extent of any distillation or teacher-model help remains unclear. It’s worth noting that even if distillation was used, it doesn’t negate DeepSeek’s achievements in training efficiency; it would simply be one more tool they exploited. Moving forward, this controversy could lead companies like OpenAI to impose stricter controls on their APIs to prevent “model cloning” via Q&A extraction ([Did China’s DeepSeek improperly obtain data?  ](https://www.studentnewsdaily.com/daily-news-article/did-chinas-deepseek-improperly-obtain-data/#:~:text=White%20House%20AI%20and%20crypto,pull%20information%20from%20OpenAI%E2%80%99s%20models)). In summary, DeepSeek’s models likely reflect *both* **independent innovation** (through open-source research and new algorithms) *and* possibly some **knowledge transfer** from existing AI, an approach that raises ethical questions but undeniably contributed to their rapid development.

## Challenges and Limitations in Scaling Efficiency  
DeepSeek’s approach, while groundbreaking, comes with certain **challenges and limitations** when considering broader AI applications and industry adoption. It’s important to recognize these caveats:

- **Inference Energy and Latency:** The DeepSeek-R1 model achieves its superior reasoning ability by employing a “chain-of-thought” reasoning process internally – essentially thinking through multiple steps to answer a query. This means that **each inference (query response) requires more computational steps and time**, as the model evaluates and refines intermediate answers ([What DeepSeek Means for AI Energy Demand - Heatmap News](https://heatmap.news/energy/deepseek-ai-energy-demand#:~:text=But%20all%20that%20artificial%20reasoning,DeepSeek%20V3%20and%20R1%20models)). Sasha Luccioni of Hugging Face notes that while DeepSeek’s training was short and efficient, its *inference is longer and more expensive per query* due to this reasoning overhead ([What DeepSeek Means for AI Energy Demand - Heatmap News](https://heatmap.news/energy/deepseek-ai-energy-demand#:~:text=But%20all%20that%20artificial%20reasoning,DeepSeek%20V3%20and%20R1%20models)). In practice, this could limit real-time or high-volume deployment of such models: they might consume *more energy serving users* than a simpler model would, especially if not optimized. For AI applications that need lightning-fast responses or must handle millions of queries, a slower, heavier reasoning process could be a bottleneck unless efficiency in inference is also addressed.

- **Jevons’ Paradox of AI Efficiency:** Making AI models cheaper and more energy-efficient per unit of performance is undoubtedly good, but it can have a double-edged effect. Several analysts warn that **dramatically lowering the cost of AI will spur much wider adoption and use of these models**, potentially *increasing* total compute and energy consumed across society ([What DeepSeek Means for AI Energy Demand - Heatmap News](https://heatmap.news/energy/deepseek-ai-energy-demand#:~:text=But%20will%20it%20really%3F%20While,data%20center%20power%20demand%20overall)). This is an AI version of Jevons’ paradox: as the “price” (energy or dollar cost) of AI drops, demand may skyrocket and **overall AI usage may grow so much that it outweighs the per-model savings** ([What DeepSeek Means for AI Energy Demand - Heatmap News](https://heatmap.news/energy/deepseek-ai-energy-demand#:~:text=But%20will%20it%20really%3F%20While,data%20center%20power%20demand%20overall)). In DeepSeek’s case, its accessible open-source model already led to a surge of new users (its app briefly surpassed ChatGPT in downloads) and many companies eyeing integration of AI. If every app, business, or device starts running LLMs because DeepSeek made it affordable, the net impact could be *more servers running 24/7*, thus higher aggregate energy draw. This doesn’t diminish DeepSeek’s technical achievement, but it shows efficiency gains must be paired with mindful deployment to truly curb energy consumption sector-wide.

- **Data and Intellectual Property Concerns:** As discussed, if DeepSeek leveraged outputs of proprietary models (like ChatGPT) to train its AI, this raises legal and ethical issues. OpenAI’s terms prohibit using its API to create competing models ([Did China’s DeepSeek improperly obtain data?  ](https://www.studentnewsdaily.com/daily-news-article/did-chinas-deepseek-improperly-obtain-data/#:~:text=It%20isn%E2%80%99t%20illegal%2C%20as%20far,%E2%80%9D%20%28from%20Vice)), and we’re already seeing potential fallout – OpenAI and Microsoft probing the situation ([Did China’s DeepSeek improperly obtain data?  ](https://www.studentnewsdaily.com/daily-news-article/did-chinas-deepseek-improperly-obtain-data/#:~:text=The%20ChatGPT%20maker%20said%20it,model%20to%20a%20smaller%20model)) ([Did China’s DeepSeek improperly obtain data?  ](https://www.studentnewsdaily.com/daily-news-article/did-chinas-deepseek-improperly-obtain-data/#:~:text=Microsoft%2C%20a%20close%20partner%20of,interface%20last%20fall%2C%C2%A0according%20to%20Bloomberg)). A **challenge for scaling such efficiency methods** is that they might run afoul of data usage policies or even lead to “AI IP” disputes. Companies aiming to replicate DeepSeek’s shortcut (distilling knowledge from a competitor’s model) risk violating terms of service or copyright on generated content. This could lead to a locked-down ecosystem where model providers throttle output or watermark it to prevent unauthorized learning. In short, one limitation of DeepSeek’s approach is that it *may not be entirely repeatable if future AI services guard against distillation*. The industry might need clearer norms or agreements on what constitutes fair use of AI outputs in training new models.

- **Reproducing the Training Feats:** DeepSeek’s training recipe — massive reinforcement learning, mixture-of-experts, etc. — is complex and not yet the standard approach in most AI labs. Successfully training a **600+ billion-parameter model via RL from scratch** (DeepSeek-R1-Zero) required considerable expertise and experimentation. Even DeepSeek’s team was surprised that pure self-play RL reached such high quality ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=To%20their%20and%20our%20surprise%2C,use%20some%20conventional%20techniques%20too)). This hints that the method may be *sensitive and hard to stabilize*. Other organizations might struggle to reproduce these results without the right talent and infrastructure. Scaling this approach to different domains (e.g. vision or multimodal models) might pose additional difficulties if a clear “self-play” or reward signal is not obvious. Moreover, techniques like MoE can introduce complexity in model serving and training (balancing experts, routing tokens efficiently). Therefore, while DeepSeek’s strategies are promising, **there’s a learning curve to implement them**, and not every AI project will immediately be able to cut its energy use by simply copying the code. The risk is that some may try and find the model doesn’t train as smoothly, or yields instabilities, without DeepSeek’s secret sauce of know-how and fine-tuning.

- **Arms Race and Diminishing Returns:** Finally, there’s a broader limitation: efficiency improvements can get overtaken by the **relentless push for higher model performance**. DeepSeek showed that what took 16,000 GPUs yesterday can be done with 2,000 today – but top-tier AI labs might respond by aiming for far larger models tomorrow since they can now afford to. In other words, the frontier will move. If OpenAI or Google adopt DeepSeek’s methods, they might train a model 10× more powerful using the same *old* budget (instead of saving money). As one analysis noted, the same efficiency gains that improve access for smaller players also enable big players to **scale to even more powerful systems on huge clusters** (“performance effect”) ([The Rise of DeepSeek: What the Headlines Miss | RAND](https://www.rand.org/pubs/commentary/2025/01/the-rise-of-deepseek-what-the-headlines-miss.html#:~:text=DeepSeek%20to%20access%20a%20given,Nvidia%27s%20latest%20generation)). For instance, if next-gen models attempt to use **100,000 GPUs for training**, any countries or companies without that scale (even if more efficient) will be left behind ([The Rise of DeepSeek: What the Headlines Miss | RAND](https://www.rand.org/pubs/commentary/2025/01/the-rise-of-deepseek-what-the-headlines-miss.html#:~:text=hundreds%20of%20thousands,play%20capabilities)). Export controls and hardware availability also factor in – DeepSeek benefited from existing stockpiles of chips, but future restrictions or the need for tens of thousands of top GPUs could **limit the approach** in regions with constrained access ([The Rise of DeepSeek: What the Headlines Miss | RAND](https://www.rand.org/pubs/commentary/2025/01/the-rise-of-deepseek-what-the-headlines-miss.html#:~:text=2,controls%20will%20affect%20China%27s%20AI)) ([The Rise of DeepSeek: What the Headlines Miss | RAND](https://www.rand.org/pubs/commentary/2025/01/the-rise-of-deepseek-what-the-headlines-miss.html#:~:text=but%20challenging%20for%20Chinese%20companies,play%20capabilities)). In summary, DeepSeek’s efficiency is a game-changer, but maintaining an efficiency edge as the whole field accelerates may prove difficult. The approach faces *diminishing returns at extreme scales and external constraints*, meaning it’s not a simple silver bullet for all of AI’s energy issues.

## Future Outlook for AI Efficiency  
DeepSeek’s pioneering work is likely to **reshape the AI landscape’s priorities** when it comes to efficiency. It has demonstrated that being clever about algorithms and architecture can beat brute-force spending – a lesson that will not be lost on the industry. We can expect a stronger emphasis on **sustainable AI development**, where model creators aggressively seek ways to cut power usage and costs. In fact, in the wake of DeepSeek R1’s release, many observers have called on the AI giants to **“work smarter, not harder”** in model training ([What DeepSeek Means for AI Energy Demand - Heatmap News](https://heatmap.news/energy/deepseek-ai-energy-demand#:~:text=Amy%20Francetic%2C%20co,efficient%20vehicle.%E2%80%9D)) ([What DeepSeek Means for AI Energy Demand - Heatmap News](https://heatmap.news/energy/deepseek-ai-energy-demand#:~:text=LLMs%20in%20the%20U,efficient%20vehicle.%E2%80%9D)). Companies like OpenAI, Google, and Meta are now under pressure to incorporate similar efficiencies; they may need to justify why their next model should cost $100+ million if an open-source upstart achieved comparable results for under $6 million. This could spur a race not just for *bigger* models, but for **better training algorithms** and more optimized hardware utilization. As one venture investor noted, hopefully DeepSeek’s success causes the big players to “find these similar efficiencies rather than…pouring more gasoline into a less fuel-efficient vehicle.” ([What DeepSeek Means for AI Energy Demand - Heatmap News](https://heatmap.news/energy/deepseek-ai-energy-demand#:~:text=Amy%20Francetic%2C%20co,efficient%20vehicle.%E2%80%9D))

In the near future, we might see **hybrid approaches** that blend DeepSeek’s ideas with existing techniques: for example, large labs doing a first pass training with self-supervised learning (as usual), then applying DeepSeek-style reinforcement learning and MoE to reach final performance with fewer extra cycles. Open-source communities could build “DeepSeek-ified” versions of popular models (imagine a LLaMA variant trained with reinforcement self-play to boost its reasoning). If widely adopted, these methods can make **AI development more accessible** – lowering the barrier for startups or academic groups to train powerful models without needing an entire data center of GPUs. This democratization would be a direct result of improved energy efficiency and cost-effectiveness.

On the other hand, the **proliferation of efficient AI** also brings policy and security considerations. DeepSeek’s rise has already triggered geopolitical concerns, with Western governments scrutinizing how a Chinese startup leapfrogged incumbents and whether export controls on chips were bypassed or need tightening ([The Rise of DeepSeek: What the Headlines Miss | RAND](https://www.rand.org/pubs/commentary/2025/01/the-rise-of-deepseek-what-the-headlines-miss.html#:~:text=1,1)) ([The Rise of DeepSeek: What the Headlines Miss | RAND](https://www.rand.org/pubs/commentary/2025/01/the-rise-of-deepseek-what-the-headlines-miss.html#:~:text=but%20challenging%20for%20Chinese%20companies,play%20capabilities)). In the U.S., there may be increased focus on preventing unauthorized distillation of proprietary models and protecting intellectual property in AI. Nonetheless, the *genie is out of the bottle*: DeepSeek’s R1 is open-source, and its ideas are now public knowledge. The long-term trajectory is likely **positive for AI sustainability** – more research will go into algorithms that *do more with less*, a win for efficiency. We have already seen the narrative around AI shift: rather than assuming ever-growing power demands, there’s a new optimism that AI can become *greener* through ingenuity ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=We%20have%20seen%20the%20release,better%20cost%20and%20energy%20efficiency)). 

In conclusion, DeepSeek’s approach provides a **glimpse of a future where AI systems are not only smart but also efficient**. Its models prove that high performance doesn’t have to come with an exorbitant energy bill. If its methods are embraced and refined, we could curb the exploding energy footprint of AI even as capabilities continue to advance. The journey won’t be without hurdles – from technical challenges in reproducing results to ensuring energy savings aren’t erased by unchecked growth in AI usage – but the impact of DeepSeek’s innovation is already reverberating. By sparking competition on efficiency, DeepSeek’s methods might very well **shape the next generation of AI** to be *leaner, cleaner, and more accessible*, steering the industry toward a more sustainable future ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=training%20can%20converge%20faster,move%20forward%20faster%20and%20cheaper)) ([Why DeepSeek could be good news for energy consumption | The Grainger College of Engineering | Illinois](https://grainger.illinois.edu/news/stories/73489#:~:text=We%20have%20seen%20the%20release,better%20cost%20and%20energy%20efficiency)).

 ([DeepSeek has rattled the AI industry. Here's a quick look at other Chinese AI models](https://techxplore.com/news/2025-01-deepseek-rattled-ai-industry-quick.html#:~:text=Image%3A%20DeepSeek%20has%20rattled%20the,Credit%3A%20AP%20Photo%2FJon%20Elswick)) ([DeepSeek: How a small AI company is shaking up US tech giants](https://usa.inquirer.net/165295/deepseek-how-a-small-chinese-ai-company-is-shaking-up-us-tech-heavyweights#:~:text=V3%20was%20trained%20at%20a,than%20US%24100%20million%20to%20develop))





**Sources:** Recent analyses and case studies on AI energy use ([Understanding AI Energy Consumption: Trends and Strategies](https://www.eweek.com/artificial-intelligence/ai-energy-consumption/#:~:text=great%20deal%20of%20computation%20resources,4)) ([Understanding AI Energy Consumption: Trends and Strategies](https://www.eweek.com/artificial-intelligence/ai-energy-consumption/#:~:text=NVIDIA%E2%80%99s%20A100%20GPU%2C%20used%20in,less%20energy%20than%20previous%20generations)) ([Understanding AI Energy Consumption: Trends and Strategies](https://www.eweek.com/artificial-intelligence/ai-energy-consumption/#:~:text=The%20main%20determinant%20of%20AI,to%20match%20the%20pace%20of)) ([Understanding AI Energy Consumption: Trends and Strategies](https://www.eweek.com/artificial-intelligence/ai-energy-consumption/#:~:text=sources%20of%20energy%20that%20result,of%20extra%20burden%20this%20will)) ([AI’s Growing Carbon Footprint – State of the Planet](https://news.climate.columbia.edu/2023/06/09/ais-growing-carbon-footprint/#:~:text=Moving%20large%20jobs%20to%20data,tons%20of%20carbon%20dioxide%20equivalent)) ([Artificial intelligence technology behind ChatGPT was built in Iowa — with a lot of water | AP News : r/Iowa](https://www.reddit.com/r/Iowa/comments/16gbhw6/artificial_intelligence_technology_behind_chatgpt/#:~:text=disclosure)) ([AI’s hidden thirst or how much water does Artificial Intelligence really drink? – Solveo](https://solveo.co/ais-hidden-thirst-or-how-much-water-does-artificial-intelligence-really-drink/#:~:text=,footprint%20an%20increasingly%20urgent%20issue)) ([AI’s hidden thirst or how much water does Artificial Intelligence really drink? – Solveo](https://solveo.co/ais-hidden-thirst-or-how-much-water-does-artificial-intelligence-really-drink/#:~:text=Let%E2%80%99s%20break%20it%20down%20further,about%20500%20milliliters%20of%20water)) ([AI’s hidden thirst or how much water does Artificial Intelligence really drink? – Solveo](https://solveo.co/ais-hidden-thirst-or-how-much-water-does-artificial-intelligence-really-drink/#:~:text=It%E2%80%99s%20like%20filling%20up%20a,speed%20we%E2%80%99ve%20come%20to%20expect)) ([AI’s Growing Carbon Footprint – State of the Planet](https://news.climate.columbia.edu/2023/06/09/ais-growing-carbon-footprint/#:~:text=Today%20data%20centers%20run%2024%2F7,those%20of%20the%20aviation%20industry)) ([AI’s Growing Carbon Footprint – State of the Planet](https://news.climate.columbia.edu/2023/06/09/ais-growing-carbon-footprint/#:~:text=Northeastern%20University%20and%20MIT%20researchers,our%20societies%20much%20more%20difficult)) ([Understanding AI Energy Consumption: Trends and Strategies](https://www.eweek.com/artificial-intelligence/ai-energy-consumption/#:~:text=Apart%20from%20carbon%20emissions%2C%20the,degradation%20but%20also%20geopolitical%20tension)) ([Understanding AI Energy Consumption: Trends and Strategies](https://www.eweek.com/artificial-intelligence/ai-energy-consumption/#:~:text=There%E2%80%99s%20a%20causal%20relationship%20between,industry%20may%20consume%20more%20energy)), and industry reports on sustainable AI practices ([Understanding AI Energy Consumption: Trends and Strategies](https://www.eweek.com/artificial-intelligence/ai-energy-consumption/#:~:text=the%20AI%20development%20community)) ([Sustainable by design: Next-generation datacenters consume zero water for cooling | The Microsoft Cloud Blog](https://www.microsoft.com/en-us/microsoft-cloud/blog/2024/12/09/sustainable-by-design-next-generation-datacenters-consume-zero-water-for-cooling/#:~:text=Beginning%20in%20August%202024%2C%20Microsoft,water%20per%20year%20per%20datacenter)) ([AI’s hidden thirst or how much water does Artificial Intelligence really drink? – Solveo](https://solveo.co/ais-hidden-thirst-or-how-much-water-does-artificial-intelligence-really-drink/#:~:text=various%20industries%2C%20so%20why%20not,it%20to%20its%20own%20operations)) ([AI’s Growing Carbon Footprint – State of the Planet](https://news.climate.columbia.edu/2023/06/09/ais-growing-carbon-footprint/#:~:text=Renewable%20energy%20use)).
